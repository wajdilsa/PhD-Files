# -*- coding: utf-8 -*-
"""RQ1 Simulation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mu8TlMljRWBhZHw3tprUndTADmbE9CyG
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid")
sns.set_palette(sns.color_palette("husl", 9))

###############################################################################
# SCENARIO DEFINITION
###############################################################################

def get_scenario_parameters(scenario="baseline"):
    """
    Returns scenario-specific parameters, including:
    - Correlation matrices, means, stds for correlated draws
    - Markov chain transition matrix for shocks
    - Carbon pricing, healthcare cost factors for cost-benefit
    - Job creation multipliers
    """
    if scenario == "baseline":
        params = {
            # Correlation matrix for [economic_growth, population_growth, base_health]
            "corr_matrix": np.array([
                [1.0,   0.3,  0.2],
                [0.3,   1.0,  0.2],
                [0.2,   0.2,  1.0]
            ]),
            # Means and standard deviations
            "means": np.array([0.01, 0.015, 0.7]),  # e.g., 1% econ growth, 1.5% pop growth, 0.7 base health
            "stds":  np.array([0.005, 0.01, 0.1]),

            # AI improvement ranges (min, max)
            "ai_energy_opt_factor": (0.01, 0.02),
            "ai_traffic_opt_factor": (0.02, 0.04),
            "ai_renewable_adoption_rate": (0.005, 0.01),
            "ai_resilience_boost": (0.01, 0.02),

            # Markov chain transition probabilities:
            # [ [P(no-shock->no-shock), P(no-shock->shock)],
            #   [P(shock->no-shock),    P(shock->shock)] ]
            "shock_transition": np.array([
                [0.90, 0.10],  # From no-shock to shock has 10% chance
                [0.50, 0.50]   # From shock to shock has 50% chance
            ]),
            "shock_impact": 0.1,  # Lower shock impact for baseline

            # Cost-Benefit Calibration
            "carbon_price": 50,   # $50 per ton of CO2
            "healthcare_cost_factor": 30,  # $30 cost per lost health percentage

            # Job Creation multipliers
            "base_jobs_factor": 500,
            "renewable_jobs_factor": 200,
            "infrastructure_jobs_factor": 100,

            # Feedback synergy
            "health_boost_factor": 0.001,  # how health factor influences econ growth
            "min_econ_growth": 0.0,
            "max_econ_growth": 0.03
        }
        return params

    elif scenario == "rapid_urbanization":
        # Higher population growth correlation & stronger job creation
        params = {
            "corr_matrix": np.array([
                [1.0,   0.4,  0.2],
                [0.4,   1.0,  0.3],
                [0.2,   0.3,  1.0]
            ]),
            "means": np.array([0.015, 0.03, 0.7]),  # e.g., 1.5% econ, 3% pop growth, 0.7 health
            "stds":  np.array([0.007, 0.015, 0.1]),

            "ai_energy_opt_factor": (0.01, 0.03),
            "ai_traffic_opt_factor": (0.03, 0.05),
            "ai_renewable_adoption_rate": (0.01, 0.02),
            "ai_resilience_boost": (0.01, 0.03),

            "shock_transition": np.array([
                [0.85, 0.15],
                [0.40, 0.60]
            ]),
            "shock_impact": 0.15,

            "carbon_price": 60,
            "healthcare_cost_factor": 25,

            "base_jobs_factor": 700,
            "renewable_jobs_factor": 300,
            "infrastructure_jobs_factor": 200,

            "health_boost_factor": 0.0015,
            "min_econ_growth": 0.0,
            "max_econ_growth": 0.05
        }
        return params

    elif scenario == "severe_climate_shock":
        # Lower correlation for econ & population, but bigger shock impact
        params = {
            "corr_matrix": np.array([
                [1.0,   0.2,  0.1],
                [0.2,   1.0,  0.1],
                [0.1,   0.1,  1.0]
            ]),
            "means": np.array([0.01, 0.01, 0.65]),
            "stds":  np.array([0.005, 0.008, 0.1]),

            "ai_energy_opt_factor": (0.01, 0.02),
            "ai_traffic_opt_factor": (0.02, 0.04),
            "ai_renewable_adoption_rate": (0.005, 0.01),
            "ai_resilience_boost": (0.01, 0.02),

            # Markov chain more likely to remain in shock once triggered
            "shock_transition": np.array([
                [0.80, 0.20],
                [0.30, 0.70]
            ]),
            "shock_impact": 0.25,

            "carbon_price": 70,
            "healthcare_cost_factor": 40,

            "base_jobs_factor": 500,
            "renewable_jobs_factor": 250,
            "infrastructure_jobs_factor": 150,

            "health_boost_factor": 0.001,
            "min_econ_growth": -0.01,  # can go negative
            "max_econ_growth": 0.03
        }
        return params

    else:
        raise ValueError(f"Unknown scenario: {scenario}")

###############################################################################
# HELPER: CORRELATED PARAMETER SAMPLING
###############################################################################

def sample_correlated_params(means, stds, corr_matrix):
    """
    Generate a single sample from a multivariate normal distribution given:
    - means: 1D array of means
    - stds: 1D array of std devs
    - corr_matrix: correlation matrix (symmetric, positive semidefinite)

    Returns a 1D array [econ_growth, pop_growth, base_health].
    """
    dim = len(means)
    # Covariance = diag(stds) * corr_matrix * diag(stds)
    cov_matrix = np.diag(stds).dot(corr_matrix).dot(np.diag(stds))

    # Cholesky decomposition
    L = np.linalg.cholesky(cov_matrix)

    # Draw from standard normal
    z = np.random.normal(size=dim)

    # Create correlated sample
    correlated = L.dot(z) + means
    return correlated

def sample_correlated_params_each_step(time_steps, means, stds, corr_matrix):
    """
    Generate an array of shape (time_steps, len(means)) from a multivariate normal
    for temporal variation. Each time step we get a new correlated draw.
    """
    dim = len(means)
    cov_matrix = np.diag(stds).dot(corr_matrix).dot(np.diag(stds))
    L = np.linalg.cholesky(cov_matrix)

    z = np.random.normal(size=(dim, time_steps))
    correlated_series = (L @ z).T + means  # shape (time_steps, dim)
    return correlated_series

###############################################################################
# HELPER: MARKOV CHAIN FOR SHOCKS
###############################################################################

def simulate_markov_shocks(time_steps, transition_matrix):
    """
    Simulates a 2-state Markov chain for "shock" vs. "no-shock" across time_steps.
    States: 0 = no-shock, 1 = shock
    transition_matrix = [[p00, p01], [p10, p11]]
    Returns an array of length time_steps with 0 or 1.
    """
    states = np.zeros(time_steps, dtype=int)
    # Start in state 0 (no shock) by default, or randomize if desired
    for t in range(1, time_steps):
        current_state = states[t-1]
        # Draw next state
        if current_state == 0:
            # Probability of no-shock -> no-shock vs. no-shock -> shock
            if np.random.rand() < transition_matrix[0,0]:
                states[t] = 0
            else:
                states[t] = 1
        else:
            # Probability of shock -> no-shock vs. shock -> shock
            if np.random.rand() < transition_matrix[1,0]:
                states[t] = 0
            else:
                states[t] = 1
    return states

###############################################################################
# MAIN SIMULATION
###############################################################################

def run_simulation(
    time_steps=24,
    scenario_params=None,
    # Initial values
    initial_population=1e5,
    initial_energy_consumption=1e6,
    initial_co2_emissions=5000,
    initial_traffic_congestion=0.6,
    initial_air_quality=80,
    initial_renewable_share=0.10,
    initial_infra_resilience=0.5
):
    """
    Run a single simulation with temporal variation of correlated parameters,
    a Markov chain for shocks, calibrated cost-benefit, and a detailed job model.
    """
    if scenario_params is None:
        scenario_params = get_scenario_parameters("baseline")

    # Sample correlated parameters for each time step
    correlated_series = sample_correlated_params_each_step(
        time_steps,
        scenario_params["means"],
        scenario_params["stds"],
        scenario_params["corr_matrix"]
    )
    # correlated_series[t] = [econ_growth_t, pop_growth_t, base_health_t]

    # Markov chain for shocks
    shock_states = simulate_markov_shocks(time_steps, scenario_params["shock_transition"])

    # Uniform draws for AI factors (treated as constant throughout the run, or you could vary them too)
    ai_energy_opt_factor = np.random.uniform(*scenario_params["ai_energy_opt_factor"])
    ai_traffic_opt_factor = np.random.uniform(*scenario_params["ai_traffic_opt_factor"])
    ai_renewable_adoption_rate = np.random.uniform(*scenario_params["ai_renewable_adoption_rate"])
    ai_resilience_boost = np.random.uniform(*scenario_params["ai_resilience_boost"])

    # Unpack other parameters
    shock_impact = scenario_params["shock_impact"]
    carbon_price = scenario_params["carbon_price"]
    healthcare_cost_factor = scenario_params["healthcare_cost_factor"]

    base_jobs_factor = scenario_params["base_jobs_factor"]
    renewable_jobs_factor = scenario_params["renewable_jobs_factor"]
    infrastructure_jobs_factor = scenario_params["infrastructure_jobs_factor"]

    health_boost_factor = scenario_params["health_boost_factor"]
    min_econ_growth = scenario_params["min_econ_growth"]
    max_econ_growth = scenario_params["max_econ_growth"]

    # Arrays for storing time series
    population_list  = np.zeros(time_steps)
    energy_list      = np.zeros(time_steps)
    co2_list         = np.zeros(time_steps)
    traffic_list     = np.zeros(time_steps)
    aqi_list         = np.zeros(time_steps)
    renewable_list   = np.zeros(time_steps)
    resilience_list  = np.zeros(time_steps)
    econ_growth_list = np.zeros(time_steps)

    # Additional metrics
    health_outcome_list  = np.zeros(time_steps)
    cost_benefit_list    = np.zeros(time_steps)
    job_sector_renewable = np.zeros(time_steps)
    job_sector_infra     = np.zeros(time_steps)
    job_sector_general   = np.zeros(time_steps)

    # State variables
    population = initial_population
    energy_consumption = initial_energy_consumption
    co2_emissions = initial_co2_emissions
    traffic_congestion = initial_traffic_congestion
    air_quality = initial_air_quality
    renewable_share = initial_renewable_share
    infra_resilience = initial_infra_resilience

    for t in range(time_steps):
        econ_growth = correlated_series[t, 0]
        pop_growth  = correlated_series[t, 1]
        base_health = correlated_series[t, 2]

        # Store current state
        population_list[t]  = population
        energy_list[t]      = energy_consumption
        co2_list[t]         = co2_emissions
        traffic_list[t]     = traffic_congestion
        aqi_list[t]         = air_quality
        renewable_list[t]   = renewable_share
        resilience_list[t]  = infra_resilience
        econ_growth_list[t] = econ_growth

        # Health factor is influenced by base_health and emissions
        # Lower CO2 -> better health, simplistic approach
        health_factor = max(0, min(1.0, base_health - (co2_emissions / 1e4)))
        health_outcome_list[t] = health_factor

        # Slight synergy: improved health factor -> boosts actual econ_growth
        synergy_growth = econ_growth + (health_factor * health_boost_factor)
        synergy_growth = max(min_econ_growth, min(max_econ_growth, synergy_growth))

        # Update population with synergy-based growth
        population *= (1 + pop_growth + synergy_growth * 0.3)

        # AI interventions
        energy_consumption *= (1 - ai_energy_opt_factor)
        traffic_congestion  *= (1 - ai_traffic_opt_factor)
        renewable_share     = min(1.0, renewable_share + ai_renewable_adoption_rate)
        infra_resilience    = min(1.0, infra_resilience * (1 + ai_resilience_boost))

        # CO2 & Air Quality
        co2_emissions = (energy_consumption * 0.005 * (1 - renewable_share) * 1e-3)
        # Degrade air_quality with CO2 & traffic
        air_quality = max(0, air_quality - (co2_emissions * 0.1) - traffic_congestion * 1.0)

        # Markov chain shock
        if shock_states[t] == 1:
            # Apply shock
            infra_resilience = max(0, infra_resilience - shock_impact)
            air_quality = max(0, air_quality - 5 * shock_impact)
            traffic_congestion = min(1.0, traffic_congestion + shock_impact * 0.1)

        # Calibrated cost-benefit:
        # Gains from reduced CO2 * carbon_price
        # Healthcare cost from lost health
        co2_cost    = co2_emissions * carbon_price
        health_loss = (1.0 - health_factor) * healthcare_cost_factor
        # Slight offset from improved infrastructure (if high resilience, lower cost)
        infra_savings = infra_resilience * 50
        cost_benefit = -co2_cost - health_loss + infra_savings
        cost_benefit_list[t] = cost_benefit

        # Detailed job creation
        # 1) Renewable sector jobs ~ renewable share
        job_rnw = renewable_share * renewable_jobs_factor
        # 2) Infrastructure jobs ~ improvements in resilience
        job_infra = infra_resilience * infrastructure_jobs_factor
        # 3) General jobs ~ synergy with base_jobs_factor + synergy_growth
        job_gen = (base_jobs_factor + synergy_growth * 1000)

        job_sector_renewable[t] = job_rnw
        job_sector_infra[t]     = job_infra
        job_sector_general[t]   = job_gen

    # Return final time series
    return {
        "Population": population_list,
        "Energy_Consumption": energy_list,
        "CO2_Emissions": co2_list,
        "Traffic_Congestion": traffic_list,
        "Air_Quality": aqi_list,
        "Renewable_Share": renewable_list,
        "Infra_Resilience": resilience_list,
        "Economic_Growth": econ_growth_list,  # raw correlated econ growth
        "Health_Factor": health_outcome_list,
        "Cost_Benefit": cost_benefit_list,
        "Job_Renewable": job_sector_renewable,
        "Job_Infrastructure": job_sector_infra,
        "Job_General": job_sector_general
    }

###############################################################################
# MONTE CARLO FRAMEWORK
###############################################################################

def run_monte_carlo_simulations(n_simulations=100, time_steps=24, scenario="baseline"):
    """
    Runs multiple simulations for a chosen scenario, returning a DataFrame of final outcomes.
    """
    scenario_params = get_scenario_parameters(scenario)

    # Store final outcomes
    results_dict = {
        "Population": [],
        "Energy_Consumption": [],
        "CO2_Emissions": [],
        "Traffic_Congestion": [],
        "Air_Quality": [],
        "Renewable_Share": [],
        "Infra_Resilience": [],
        "Economic_Growth": [],
        "Health_Factor": [],
        "Cost_Benefit": [],
        "Job_Renewable": [],
        "Job_Infrastructure": [],
        "Job_General": []
    }

    for _ in range(n_simulations):
        sim_results = run_simulation(time_steps=time_steps, scenario_params=scenario_params)

        # Append final values from the last time step
        for key in results_dict.keys():
            results_dict[key].append(sim_results[key][-1])

    df_final = pd.DataFrame(results_dict)
    return df_final

###############################################################################
# ANALYSIS & VISUALIZATION
###############################################################################

def analyze_uncertainty(df_results, title="Scenario Analysis"):
    """
    Analyze the distribution of final results, compute confidence intervals,
    and visualize the outputs.
    """
    summary_stats = df_results.describe(percentiles=[0.025, 0.5, 0.975])
    print(f"=== {title} ===")
    print(summary_stats)

    # Example: Extract 95% confidence interval for CO2 Emissions
    co2_lower_95 = summary_stats.loc["2.5%", "CO2_Emissions"]
    co2_median   = summary_stats.loc["50%",  "CO2_Emissions"]
    co2_upper_95 = summary_stats.loc["97.5%", "CO2_Emissions"]

    print(f"\n95% CI for CO2 Emissions: [{co2_lower_95:.4f}, {co2_upper_95:.4f}]")
    print(f"Median CO2 Emissions: {co2_median:.4f}\n")

    # Plot histograms for key outputs
    columns_to_plot = [
        "CO2_Emissions", "Energy_Consumption", "Traffic_Congestion",
        "Air_Quality", "Cost_Benefit", "Job_Renewable",
        "Job_Infrastructure", "Job_General"
    ]

    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.flatten()

    for i, col in enumerate(columns_to_plot):
        sns.histplot(df_results[col], ax=axes[i], kde=True)
        axes[i].set_title(col)

    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

###############################################################################
# DEMONSTRATION
###############################################################################

if __name__ == "__main__":
    # 1) Baseline scenario
    df_baseline = run_monte_carlo_simulations(n_simulations=200, time_steps=24, scenario="baseline")
    analyze_uncertainty(df_baseline, title="Baseline Scenario")

    # 2) Rapid Urbanization
    df_rapid = run_monte_carlo_simulations(n_simulations=200, time_steps=24, scenario="rapid_urbanization")
    analyze_uncertainty(df_rapid, title="Rapid Urbanization Scenario")

    # 3) Severe Climate Shock
    df_shock = run_monte_carlo_simulations(n_simulations=200, time_steps=24, scenario="severe_climate_shock")
    analyze_uncertainty(df_shock, title="Severe Climate Shock Scenario")



#This simulation aligns with your research objectives:

#Research Question 1: Identifies key components of AI interventions (e.g., energy optimization, resilience boosts) for climate change mitigation.
#Research Question 4: Provides a framework for evaluating AI solutions using measurable urban metrics under diverse scenarios.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid")
sns.set_palette(sns.color_palette("husl", 9))

###############################################################################
# SCENARIO DEFINITION
###############################################################################

def get_scenario_parameters(scenario="baseline"):
    """
    Returns scenario-specific parameters for correlated draws, Markov chain transitions,
    AI improvement ranges, cost-benefit calibrations, job creation multipliers, plus
    new variables: waste management & water scarcity.
    """
    if scenario == "baseline":
        params = {
            # Correlation matrix for [economic_growth, population_growth, base_health, base_waste, base_water]
            # Example 5x5 matrix with moderate correlations
            "corr_matrix": np.array([
                [1.0,  0.3,  0.2,  0.1,  0.1],
                [0.3,  1.0,  0.2,  0.2,  0.1],
                [0.2,  0.2,  1.0,  0.2,  0.1],
                [0.1,  0.2,  0.2,  1.0,  0.3],
                [0.1,  0.1,  0.1,  0.3,  1.0]
            ]),
            # Means and stds for [econ_growth, pop_growth, base_health, waste_baseline, water_baseline]
            "means": np.array([0.01, 0.015, 0.7, 0.5, 0.5]),
            "stds":  np.array([0.005, 0.01, 0.1, 0.1, 0.1]),

            # AI improvement ranges
            "ai_energy_opt_factor": (0.01, 0.02),
            "ai_traffic_opt_factor": (0.02, 0.04),
            "ai_renewable_adoption_rate": (0.005, 0.01),
            "ai_resilience_boost": (0.01, 0.02),

            # Markov chain transition probabilities for shocks
            "shock_transition": np.array([
                [0.90, 0.10],
                [0.50, 0.50]
            ]),
            "shock_impact": 0.1,

            # Cost-Benefit Calibration
            "carbon_price": 50,
            "healthcare_cost_factor": 30,

            # Job Creation multipliers
            "base_jobs_factor": 500,
            "renewable_jobs_factor": 200,
            "infrastructure_jobs_factor": 100,

            # Feedback synergy
            "health_boost_factor": 0.001,
            "min_econ_growth": 0.0,
            "max_econ_growth": 0.03,

            # New: water scarcity & waste management
            "waste_improvement_factor": 0.01,  # how AI can improve waste mgmt each step
            "water_scarcity_risk_factor": 0.02, # how quickly water scarcity can degrade if not addressed
            "water_adaptation_factor": 0.005,   # AI adaptation for water conservation
            "water_crisis_threshold": 0.75      # if water scarcity > 0.75, triggers predictive analytics
        }
        return params

    elif scenario == "rapid_urbanization":
        # Stronger population growth, more waste generation, higher water stress
        params = {
            "corr_matrix": np.array([
                [1.0,  0.4,  0.2,  0.2,  0.1],
                [0.4,  1.0,  0.3,  0.3,  0.2],
                [0.2,  0.3,  1.0,  0.3,  0.2],
                [0.2,  0.3,  0.3,  1.0,  0.4],
                [0.1,  0.2,  0.2,  0.4,  1.0]
            ]),
            "means": np.array([0.02, 0.03, 0.7, 0.6, 0.6]),
            "stds":  np.array([0.007, 0.015, 0.1, 0.15, 0.15]),

            "ai_energy_opt_factor": (0.01, 0.03),
            "ai_traffic_opt_factor": (0.03, 0.05),
            "ai_renewable_adoption_rate": (0.01, 0.02),
            "ai_resilience_boost": (0.01, 0.03),

            "shock_transition": np.array([
                [0.85, 0.15],
                [0.40, 0.60]
            ]),
            "shock_impact": 0.15,

            "carbon_price": 60,
            "healthcare_cost_factor": 25,

            "base_jobs_factor": 700,
            "renewable_jobs_factor": 300,
            "infrastructure_jobs_factor": 200,

            "health_boost_factor": 0.0015,
            "min_econ_growth": 0.0,
            "max_econ_growth": 0.05,

            "waste_improvement_factor": 0.015,
            "water_scarcity_risk_factor": 0.03,
            "water_adaptation_factor": 0.008,
            "water_crisis_threshold": 0.8
        }
        return params

    elif scenario == "severe_climate_shock":
        # Lower correlation for econ & population, bigger shock impact, bigger water stress
        params = {
            "corr_matrix": np.array([
                [1.0,  0.2,  0.1,  0.1,  0.2],
                [0.2,  1.0,  0.1,  0.2,  0.3],
                [0.1,  0.1,  1.0,  0.2,  0.3],
                [0.1,  0.2,  0.2,  1.0,  0.4],
                [0.2,  0.3,  0.3,  0.4,  1.0]
            ]),
            "means": np.array([0.01, 0.01, 0.65, 0.55, 0.6]),
            "stds":  np.array([0.005, 0.01, 0.1, 0.15, 0.15]),

            "ai_energy_opt_factor": (0.01, 0.02),
            "ai_traffic_opt_factor": (0.02, 0.04),
            "ai_renewable_adoption_rate": (0.005, 0.01),
            "ai_resilience_boost": (0.01, 0.02),

            "shock_transition": np.array([
                [0.80, 0.20],
                [0.30, 0.70]
            ]),
            "shock_impact": 0.25,

            "carbon_price": 70,
            "healthcare_cost_factor": 40,

            "base_jobs_factor": 500,
            "renewable_jobs_factor": 250,
            "infrastructure_jobs_factor": 150,

            "health_boost_factor": 0.001,
            "min_econ_growth": -0.01,
            "max_econ_growth": 0.03,

            "waste_improvement_factor": 0.01,
            "water_scarcity_risk_factor": 0.04,
            "water_adaptation_factor": 0.01,
            "water_crisis_threshold": 0.85
        }
        return params

    else:
        raise ValueError(f"Unknown scenario: {scenario}")

###############################################################################
# HELPER: CORRELATED PARAMETER SAMPLING
###############################################################################

def sample_correlated_params_each_step(time_steps, means, stds, corr_matrix):
    """
    Generate an array of shape (time_steps, len(means)) from a multivariate normal
    for temporal variation. Each time step gets a new correlated draw.
    """
    dim = len(means)
    cov_matrix = np.diag(stds).dot(corr_matrix).dot(np.diag(stds))
    L = np.linalg.cholesky(cov_matrix)
    z = np.random.normal(size=(dim, time_steps))
    correlated_series = (L @ z).T + means  # shape (time_steps, dim)
    return correlated_series

###############################################################################
# HELPER: MARKOV CHAIN FOR SHOCKS
###############################################################################

def simulate_markov_shocks(time_steps, transition_matrix):
    """
    Simulates a 2-state Markov chain for "shock" vs. "no-shock" across time_steps.
    States: 0 = no-shock, 1 = shock
    transition_matrix = [[p00, p01],[p10, p11]]
    Returns an array of length time_steps with 0 or 1.
    """
    states = np.zeros(time_steps, dtype=int)
    for t in range(1, time_steps):
        current_state = states[t-1]
        if current_state == 0:
            if np.random.rand() < transition_matrix[0,0]:
                states[t] = 0
            else:
                states[t] = 1
        else:
            if np.random.rand() < transition_matrix[1,0]:
                states[t] = 0
            else:
                states[t] = 1
    return states

###############################################################################
# MAIN SIMULATION WITH ENHANCED AI INTERVENTIONS & NEW VARIABLES
###############################################################################

def run_simulation(
    time_steps=24,
    scenario_params=None,
    # Initial values
    initial_population=1e5,
    initial_energy_consumption=1e6,
    initial_co2_emissions=5000,
    initial_traffic_congestion=0.6,
    initial_air_quality=80,
    initial_renewable_share=0.10,
    initial_infra_resilience=0.5,
    initial_waste_efficiency=0.4,  # 0=poor, 1=perfect
    initial_water_scarcity=0.4     # 0=abundant, 1=extreme scarcity
):
    """
    Run a single simulation with:
    - Additional variables: waste management efficiency, water scarcity
    - Enhanced AI: dynamic responses to emerging challenges + early warning
    - Markov chain for shocks + correlated parameter draws
    - Calibrated cost-benefit & job creation
    """

    if scenario_params is None:
        scenario_params = get_scenario_parameters("baseline")

    # Step 1: Correlated parameters at each step
    correlated_series = sample_correlated_params_each_step(
        time_steps,
        scenario_params["means"],
        scenario_params["stds"],
        scenario_params["corr_matrix"]
    )
    # correlated_series[t] = [econ_growth, pop_growth, base_health, waste_baseline, water_baseline]

    # Step 2: Markov chain for shocks
    shock_states = simulate_markov_shocks(time_steps, scenario_params["shock_transition"])

    # Step 3: AI intervention factors
    ai_energy_opt_factor       = np.random.uniform(*scenario_params["ai_energy_opt_factor"])
    ai_traffic_opt_factor      = np.random.uniform(*scenario_params["ai_traffic_opt_factor"])
    ai_renewable_adoption_rate = np.random.uniform(*scenario_params["ai_renewable_adoption_rate"])
    ai_resilience_boost        = np.random.uniform(*scenario_params["ai_resilience_boost"])

    # Additional new parameters
    shock_impact                = scenario_params["shock_impact"]
    carbon_price                = scenario_params["carbon_price"]
    healthcare_cost_factor      = scenario_params["healthcare_cost_factor"]
    base_jobs_factor            = scenario_params["base_jobs_factor"]
    renewable_jobs_factor       = scenario_params["renewable_jobs_factor"]
    infrastructure_jobs_factor  = scenario_params["infrastructure_jobs_factor"]
    health_boost_factor         = scenario_params["health_boost_factor"]
    min_econ_growth             = scenario_params["min_econ_growth"]
    max_econ_growth             = scenario_params["max_econ_growth"]

    waste_improvement_factor    = scenario_params["waste_improvement_factor"]
    water_scarcity_risk_factor  = scenario_params["water_scarcity_risk_factor"]
    water_adaptation_factor     = scenario_params["water_adaptation_factor"]
    water_crisis_threshold      = scenario_params["water_crisis_threshold"]

    # Step 4: Initialize arrays for results
    population_arr         = np.zeros(time_steps)
    energy_arr             = np.zeros(time_steps)
    co2_arr                = np.zeros(time_steps)
    traffic_arr            = np.zeros(time_steps)
    aqi_arr                = np.zeros(time_steps)
    renewable_arr          = np.zeros(time_steps)
    resilience_arr         = np.zeros(time_steps)
    econ_growth_arr        = np.zeros(time_steps)
    health_factor_arr      = np.zeros(time_steps)
    cost_benefit_arr       = np.zeros(time_steps)
    waste_efficiency_arr   = np.zeros(time_steps)
    water_scarcity_arr     = np.zeros(time_steps)

    job_renewable_arr      = np.zeros(time_steps)
    job_infra_arr          = np.zeros(time_steps)
    job_general_arr        = np.zeros(time_steps)

    # Step 5: Initialize state variables
    population          = initial_population
    energy_consumption  = initial_energy_consumption
    co2_emissions       = initial_co2_emissions
    traffic_congestion  = initial_traffic_congestion
    air_quality         = initial_air_quality
    renewable_share     = initial_renewable_share
    infra_resilience    = initial_infra_resilience
    waste_efficiency    = initial_waste_efficiency
    water_scarcity      = initial_water_scarcity

    # Step 6: Main simulation loop
    for t in range(time_steps):
        econ_growth_t       = correlated_series[t, 0]
        pop_growth_t        = correlated_series[t, 1]
        base_health_t       = correlated_series[t, 2]
        waste_baseline_t    = correlated_series[t, 3]
        water_baseline_t    = correlated_series[t, 4]

        # Store current state
        population_arr[t]       = population
        energy_arr[t]           = energy_consumption
        co2_arr[t]              = co2_emissions
        traffic_arr[t]          = traffic_congestion
        aqi_arr[t]              = air_quality
        renewable_arr[t]        = renewable_share
        resilience_arr[t]       = infra_resilience
        econ_growth_arr[t]      = econ_growth_t
        waste_efficiency_arr[t] = waste_efficiency
        water_scarcity_arr[t]   = water_scarcity

        # Health factor influenced by base_health & CO2
        health_factor = max(0, min(1.0, base_health_t - (co2_emissions / 1e4)))
        health_factor_arr[t] = health_factor

        # Adaptive AI: intensify if CO2 or water scarcity are high
        adaptive_ai_energy = ai_energy_opt_factor
        adaptive_ai_water  = water_adaptation_factor
        # If CO2 is too high:
        if co2_emissions > 4000:
            adaptive_ai_energy *= 1.2  # 20% stronger energy optimization
        # If water scarcity is above baseline:
        if water_scarcity > 0.5:
            adaptive_ai_water *= 1.2

        # Early warning for water crisis
        if water_scarcity > water_crisis_threshold:
            # Preemptive water infrastructure investment
            infra_resilience = min(1.0, infra_resilience * (1 + adaptive_ai_water * 0.5))
            # Additional cost for water crisis management, but helps reduce water scarcity
            water_scarcity = max(0, water_scarcity - 0.05)

        # Population growth synergy with health & econ
        synergy_growth = econ_growth_t + health_factor * health_boost_factor
        synergy_growth = max(min_econ_growth, min(max_econ_growth, synergy_growth))
        population *= (1 + pop_growth_t + synergy_growth * 0.3)

        # Waste management improvement each step, but also depends on baseline
        waste_efficiency = min(1.0, waste_efficiency + waste_improvement_factor * (1 - waste_efficiency))

        # Water scarcity dynamic
        # Worsens with population + base water factor + shock events
        water_scarcity += (water_scarcity_risk_factor * pop_growth_t * 2)
        # Try to reduce water scarcity with adaptive AI water actions
        water_scarcity = max(0, water_scarcity - adaptive_ai_water)

        # AI interventions
        energy_consumption *= (1 - adaptive_ai_energy)
        traffic_congestion  *= (1 - ai_traffic_opt_factor)
        renewable_share     = min(1.0, renewable_share + ai_renewable_adoption_rate)
        infra_resilience    = min(1.0, infra_resilience * (1 + ai_resilience_boost))

        # CO2 & Air Quality
        # Considering waste efficiency can reduce overall emissions slightly
        co2_emissions = (energy_consumption * 0.005 * (1 - renewable_share) * 1e-3)
        co2_emissions *= (1 - 0.1 * waste_efficiency)  # better waste mgmt -> reduce CO2
        air_quality    = max(0, air_quality - (co2_emissions * 0.1) - (traffic_congestion * 1.0))

        # Markov chain shock
        if shock_states[t] == 1:
            infra_resilience = max(0, infra_resilience - shock_impact)
            air_quality      = max(0, air_quality - 5 * shock_impact)
            traffic_congestion = min(1.0, traffic_congestion + shock_impact * 0.1)
            water_scarcity     = min(1.0, water_scarcity + shock_impact * 0.05)

        # Cost-Benefit (calibrated)
        co2_cost    = co2_emissions * carbon_price
        health_loss = (1.0 - health_factor) * healthcare_cost_factor
        infra_savings = infra_resilience * 50
        # Factor in waste management as a positive benefit
        waste_benefit = waste_efficiency * 20
        cost_benefit = -co2_cost - health_loss + infra_savings + waste_benefit

        cost_benefit_arr[t] = cost_benefit

        # Job creation
        job_rnw = renewable_share * renewable_jobs_factor
        job_infra = infra_resilience * infrastructure_jobs_factor
        job_gen = (base_jobs_factor + synergy_growth * 1000)
        job_renewable_arr[t] = job_rnw
        job_infra_arr[t]     = job_infra
        job_general_arr[t]   = job_gen

    # Return final results
    return {
        "Population": population_arr,
        "Energy_Consumption": energy_arr,
        "CO2_Emissions": co2_arr,
        "Traffic_Congestion": traffic_arr,
        "Air_Quality": aqi_arr,
        "Renewable_Share": renewable_arr,
        "Infra_Resilience": resilience_arr,
        "Economic_Growth": econ_growth_arr,
        "Health_Factor": health_factor_arr,
        "Cost_Benefit": cost_benefit_arr,
        "Waste_Efficiency": waste_efficiency_arr,
        "Water_Scarcity": water_scarcity_arr,
        "Job_Renewable": job_renewable_arr,
        "Job_Infrastructure": job_infra_arr,
        "Job_General": job_general_arr
    }

###############################################################################
# MONTE CARLO SIMULATIONS
###############################################################################

def run_monte_carlo_simulations(n_simulations=100, time_steps=24, scenario="baseline"):
    """
    Runs multiple simulations for a chosen scenario, returning a list of time-series results
    (one DataFrame per simulation or aggregated final values).
    For easier post-processing, we'll store the final step in a single DF.
    """
    scenario_params = get_scenario_parameters(scenario)

    results_final = {
        "Population": [],
        "Energy_Consumption": [],
        "CO2_Emissions": [],
        "Traffic_Congestion": [],
        "Air_Quality": [],
        "Renewable_Share": [],
        "Infra_Resilience": [],
        "Economic_Growth": [],
        "Health_Factor": [],
        "Cost_Benefit": [],
        "Waste_Efficiency": [],
        "Water_Scarcity": [],
        "Job_Renewable": [],
        "Job_Infrastructure": [],
        "Job_General": []
    }

    # For aggregated time-series analysis, you might store each run’s full array
    # into a 3D structure or list of dataframes. Here, we just store final values.

    for _ in range(n_simulations):
        sim_results = run_simulation(time_steps=time_steps, scenario_params=scenario_params)

        # Extract final step for each metric
        for k in results_final.keys():
            results_final[k].append(sim_results[k][-1])

    return pd.DataFrame(results_final)

###############################################################################
# REPORTING & VISUALIZATION
###############################################################################

def plot_time_series(sim_results, title="Time-Series Visualization"):
    """
    Given a single simulation result (dict of arrays), produce time-series plots
    for key metrics to illustrate changes over time.
    """
    df = pd.DataFrame(sim_results)
    time_index = np.arange(len(df))

    fig, axes = plt.subplots(3, 3, figsize=(15, 12))
    axes = axes.flatten()

    # A few examples: CO2, Air Quality, Water Scarcity, etc.
    sns.lineplot(x=time_index, y="CO2_Emissions", data=df, ax=axes[0], label="CO2")
    axes[0].set_title("CO2 Emissions Over Time")

    sns.lineplot(x=time_index, y="Air_Quality", data=df, ax=axes[1], label="AQI")
    axes[1].set_title("Air Quality (AQI) Over Time")

    sns.lineplot(x=time_index, y="Water_Scarcity", data=df, ax=axes[2], label="Water Scarcity")
    axes[2].set_title("Water Scarcity Over Time")

    sns.lineplot(x=time_index, y="Waste_Efficiency", data=df, ax=axes[3], label="Waste Efficiency")
    axes[3].set_title("Waste Management Efficiency Over Time")

    sns.lineplot(x=time_index, y="Cost_Benefit", data=df, ax=axes[4], label="Cost-Benefit")
    axes[4].set_title("Cost-Benefit Over Time")

    sns.lineplot(x=time_index, y="Population", data=df, ax=axes[5], label="Population")
    axes[5].set_title("Population Growth Over Time")

    sns.lineplot(x=time_index, y="Infra_Resilience", data=df, ax=axes[6], label="Resilience")
    axes[6].set_title("Infrastructure Resilience Over Time")

    sns.lineplot(x=time_index, y="Job_General", data=df, ax=axes[7], label="General Jobs")
    sns.lineplot(x=time_index, y="Job_Renewable", data=df, ax=axes[7], label="Renewable Jobs")
    sns.lineplot(x=time_index, y="Job_Infrastructure", data=df, ax=axes[7], label="Infra Jobs")
    axes[7].set_title("Job Creation Over Time")
    axes[7].legend()

    sns.lineplot(x=time_index, y="Traffic_Congestion", data=df, ax=axes[8], label="Traffic")
    axes[8].set_title("Traffic Congestion Over Time")

    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

def create_heatmap(df_results, title="Heatmap of Final Outcomes"):
    """
    Create a heatmap of correlations between final outcome variables.
    """
    corr = df_results.corr()
    plt.figure(figsize=(10, 7))
    sns.heatmap(corr, annot=True, cmap="viridis", fmt=".2f")
    plt.title(title)
    plt.tight_layout()
    plt.show()

def stakeholder_report(df_results, scenario_name="Baseline"):
    """
    Print a structured summary highlighting economic, environmental,
    and social benefits for stakeholders.
    """
    print(f"================ {scenario_name.upper()} SCENARIO REPORT ================")
    # Basic stats
    summary_stats = df_results.describe(percentiles=[0.025, 0.5, 0.975])
    print(summary_stats)

    # Potential additional analysis or text explanation
    # For instance, highlight average cost-benefit
    avg_cost_benefit = df_results["Cost_Benefit"].mean()
    avg_co2 = df_results["CO2_Emissions"].mean()
    avg_jobs = (df_results["Job_General"] + df_results["Job_Renewable"] + df_results["Job_Infrastructure"]).mean()

    print("\nKey Highlights:")
    print(f" - Average CO2 Emissions: {avg_co2:.2f} tons (final step).")
    print(f" - Mean Cost-Benefit Value: ${avg_cost_benefit:.2f} at final step.")
    print(f" - Average Total Jobs Created: {avg_jobs:.1f} (across simulations).")

    print("\nEconomic Benefits:")
    print(" - Positive cost-benefit values indicate net savings or revenues.")
    print(" - Job creation includes general, renewable, and infrastructure sectors.\n")

    print("Environmental Gains:")
    print(" - Waste Management Efficiency and Water Scarcity metrics track sustainability.")
    print(" - Lower CO2 and higher Air Quality reflect effective climate strategies.\n")

    print("Social Outcomes:")
    print(" - Health Factor synergy helps reduce healthcare costs.")
    print(" - Infrastructure resilience mitigates shock impacts on communities.")
    print("====================================================================\n")

###############################################################################
# DEMONSTRATION
###############################################################################

if __name__ == "__main__":
    # Single run for time-series visualization
    single_run_results = run_simulation(time_steps=24, scenario_params=get_scenario_parameters("baseline"))
    plot_time_series(single_run_results, title="Sample Baseline Run - Time Series")

    # Monte Carlo for baseline scenario
    df_baseline = run_monte_carlo_simulations(n_simulations=100, time_steps=24, scenario="baseline")
    create_heatmap(df_baseline, title="Baseline Scenario Final Outcomes Correlation")
    stakeholder_report(df_baseline, scenario_name="Baseline")

    # Monte Carlo for rapid urbanization
    df_rapid = run_monte_carlo_simulations(n_simulations=100, time_steps=24, scenario="rapid_urbanization")
    create_heatmap(df_rapid, title="Rapid Urbanization Scenario Final Outcomes Correlation")
    stakeholder_report(df_rapid, scenario_name="Rapid Urbanization")

    # Monte Carlo for severe climate shock
    df_shock = run_monte_carlo_simulations(n_simulations=100, time_steps=24, scenario="severe_climate_shock")
    create_heatmap(df_shock, title="Severe Climate Shock Scenario Final Outcomes Correlation")
    stakeholder_report(df_shock, scenario_name="Severe Climate Shock")